/var/spool/slurm-llnl/d/job761169/slurm_script: line 22: nvcc: command not found
/Arontier/People/hnefa335/anaconda3/envs/comet/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
2021-09-16 14:50:59,436 - INFO - Model Load
/Arontier/People/hnefa335/anaconda3/envs/comet/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
2021-09-16 14:51:04,334 - INFO - Epoch : 1/100, Batch : 1/391, train loss : 2.3026, accuracy : 0.1016
2021-09-16 14:59:55,739 - INFO - Epoch : 1/100, Batch : 391/391, train loss : 0.8490, accuracy : 0.8495
2021-09-16 14:59:57,143 - INFO - Epoch : 1/100, Batch : 1/157, test loss : 0.1116, accuracy : 0.9688
2021-09-16 15:00:34,599 - INFO - Epoch : 1/100, Batch : 157/157, test loss : 0.0903, accuracy : 0.9726
2021-09-16 15:00:42,597 - INFO - Epoch : 2/100, Batch : 1/391, train loss : 0.2992, accuracy : 0.8984
2021-09-16 15:09:36,476 - INFO - Epoch : 2/100, Batch : 391/391, train loss : 0.3979, accuracy : 0.8664
2021-09-16 15:09:38,038 - INFO - Epoch : 2/100, Batch : 1/157, test loss : 0.0915, accuracy : 0.9688
2021-09-16 15:10:15,271 - INFO - Epoch : 2/100, Batch : 157/157, test loss : 0.0825, accuracy : 0.9729
2021-09-16 15:10:25,541 - INFO - Epoch : 3/100, Batch : 1/391, train loss : 0.4092, accuracy : 0.8438
2021-09-16 15:19:18,311 - INFO - Epoch : 3/100, Batch : 391/391, train loss : 0.3524, accuracy : 0.8814
2021-09-16 15:19:19,225 - INFO - Epoch : 3/100, Batch : 1/157, test loss : 0.1821, accuracy : 0.9375
2021-09-16 15:19:56,495 - INFO - Epoch : 3/100, Batch : 157/157, test loss : 0.0964, accuracy : 0.9699
2021-09-16 15:20:09,808 - INFO - Epoch : 4/100, Batch : 1/391, train loss : 0.6963, accuracy : 0.7500
2021-09-16 15:29:02,375 - INFO - Epoch : 4/100, Batch : 391/391, train loss : 0.3366, accuracy : 0.8857
2021-09-16 15:29:07,555 - INFO - Epoch : 4/100, Batch : 1/157, test loss : 0.1209, accuracy : 0.9688
2021-09-16 15:29:44,731 - INFO - Epoch : 4/100, Batch : 157/157, test loss : 0.0661, accuracy : 0.9783
2021-09-16 15:29:58,216 - INFO - Epoch : 5/100, Batch : 1/391, train loss : 0.2308, accuracy : 0.9297
2021-09-16 15:38:51,380 - INFO - Epoch : 5/100, Batch : 391/391, train loss : 0.3066, accuracy : 0.8945
2021-09-16 15:38:52,131 - INFO - Epoch : 5/100, Batch : 1/157, test loss : 0.1424, accuracy : 0.9688
2021-09-16 15:39:29,459 - INFO - Epoch : 5/100, Batch : 157/157, test loss : 0.0767, accuracy : 0.9757
2021-09-16 15:39:34,956 - INFO - Epoch : 6/100, Batch : 1/391, train loss : 0.2615, accuracy : 0.9062
2021-09-16 15:48:28,050 - INFO - Epoch : 6/100, Batch : 391/391, train loss : 0.2924, accuracy : 0.8997
2021-09-16 15:48:29,601 - INFO - Epoch : 6/100, Batch : 1/157, test loss : 0.0872, accuracy : 0.9531
2021-09-16 15:49:06,977 - INFO - Epoch : 6/100, Batch : 157/157, test loss : 0.0545, accuracy : 0.9814
2021-09-16 15:49:16,213 - INFO - Epoch : 7/100, Batch : 1/391, train loss : 0.3949, accuracy : 0.8594
2021-09-16 15:58:08,982 - INFO - Epoch : 7/100, Batch : 391/391, train loss : 0.2714, accuracy : 0.9065
2021-09-16 15:58:09,675 - INFO - Epoch : 7/100, Batch : 1/157, test loss : 0.0739, accuracy : 0.9688
2021-09-16 15:58:46,953 - INFO - Epoch : 7/100, Batch : 157/157, test loss : 0.0586, accuracy : 0.9821
2021-09-16 15:58:59,095 - INFO - Epoch : 8/100, Batch : 1/391, train loss : 0.2308, accuracy : 0.9219
2021-09-16 16:07:51,782 - INFO - Epoch : 8/100, Batch : 391/391, train loss : 0.2610, accuracy : 0.9106
2021-09-16 16:07:52,685 - INFO - Epoch : 8/100, Batch : 1/157, test loss : 0.1071, accuracy : 0.9844
2021-09-16 16:08:29,957 - INFO - Epoch : 8/100, Batch : 157/157, test loss : 0.0612, accuracy : 0.9828
2021-09-16 16:08:42,295 - INFO - Epoch : 9/100, Batch : 1/391, train loss : 0.2704, accuracy : 0.9219
2021-09-16 16:17:35,272 - INFO - Epoch : 9/100, Batch : 391/391, train loss : 0.2450, accuracy : 0.9145
2021-09-16 16:17:36,913 - INFO - Epoch : 9/100, Batch : 1/157, test loss : 0.0183, accuracy : 1.0000
2021-09-16 16:18:14,176 - INFO - Epoch : 9/100, Batch : 157/157, test loss : 0.0545, accuracy : 0.9838
2021-09-16 16:18:23,813 - INFO - Epoch : 10/100, Batch : 1/391, train loss : 0.3180, accuracy : 0.9062
2021-09-16 16:27:16,872 - INFO - Epoch : 10/100, Batch : 391/391, train loss : 0.2396, accuracy : 0.9172
2021-09-16 16:27:18,099 - INFO - Epoch : 10/100, Batch : 1/157, test loss : 0.0295, accuracy : 0.9688
2021-09-16 16:27:55,640 - INFO - Epoch : 10/100, Batch : 157/157, test loss : 0.0569, accuracy : 0.9818
2021-09-16 16:28:17,930 - INFO - Epoch : 11/100, Batch : 1/391, train loss : 0.2212, accuracy : 0.9219
slurmstepd-learningQ1: error: *** JOB 761169 ON learningQ1 CANCELLED AT 2021-09-16T16:31:28 ***
