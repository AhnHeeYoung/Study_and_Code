{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import models\n",
    "from data_aug.contrastive_learning_dataset import ContrastiveLearningDataset\n",
    "from models.resnet_simclr import ResNetSimCLR\n",
    "from simclr import SimCLR\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from utils import save_config_file, accuracy, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.writer = SummaryWriter()\n",
    "        logging.basicConfig(filename=os.path.join(self.writer.log_dir, 'training.log'), level=logging.DEBUG)\n",
    "        \n",
    "        self.device = 'cpu'\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.device)\n",
    "\n",
    "    def info_nce_loss(self, features):\n",
    "\n",
    "        labels = torch.cat([torch.arange(256) for i in range(2)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.device)\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        # assert similarity_matrix.shape == (\n",
    "        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # discard the main diagonal from both: labels and similarities matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # select and combine multiple positives\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "        # select only the negatives the negatives\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.device)\n",
    "\n",
    "        logits = logits / 0.07\n",
    "        return logits, labels\n",
    "\n",
    "    def train(self, train_loader):\n",
    "\n",
    "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
    "\n",
    "        # save config file\n",
    "        save_config_file(self.writer.log_dir, self.args)\n",
    "\n",
    "        n_iter = 0\n",
    "        logging.info(f\"Start SimCLR training for {self.args.epochs} epochs.\")\n",
    "        logging.info(f\"Training with gpu: {self.args.disable_cuda}.\")\n",
    "\n",
    "        for epoch_counter in range(self.args.epochs):\n",
    "            for images, _ in tqdm(train_loader):\n",
    "                images = torch.cat(images, dim=0)\n",
    "\n",
    "                images = images.to(self.args.device)\n",
    "\n",
    "                with autocast(enabled=self.args.fp16_precision):\n",
    "                    features = self.model(images)\n",
    "                    logits, labels = self.info_nce_loss(features)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                if n_iter % self.args.logeverynsteps == 0:\n",
    "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "                    self.writer.add_scalar('loss', loss, global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top1', top1[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top5', top5[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('learning_rate', self.scheduler.get_lr()[0], global_step=n_iter)\n",
    "\n",
    "                    \n",
    "                top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "                logging.info('loss : ', loss)\n",
    "                logging.info('acc/top1 :', top1[0])\n",
    "                logging.info('acc/top5 :', top5[0])\n",
    "                \n",
    "                    \n",
    "                n_iter += 1\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "\n",
    "            # warmup for the first 10 epochs\n",
    "            if epoch_counter >= 10:\n",
    "                self.scheduler.step()\n",
    "            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "\n",
    "        logging.info(\"Training has finished.\")\n",
    "        # save model checkpoints\n",
    "        checkpoint_name = 'checkpoint_{:04d}.pth.tar'.format(self.args.epochs)\n",
    "        save_checkpoint({\n",
    "            'epoch': self.args.epochs,\n",
    "            'arch': self.args.arch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }, is_best=False, filename=os.path.join(self.writer.log_dir, checkpoint_name))\n",
    "        logging.info(f\"Model checkpoint and metadata has been saved at {self.writer.log_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = ContrastiveLearningDataset('./datasets')\n",
    "\n",
    "train_dataset = dataset.get_dataset('stl10', 2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=True,\n",
    "    num_workers=1, pin_memory=False, drop_last=True)\n",
    "\n",
    "model = ResNetSimCLR(base_model='resnet18', out_dim=128)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.0003, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                       last_epoch=-1)\n",
    "\n",
    "simclr = SimCLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/390 [00:16<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for images, y in tqdm(train_loader):\n",
    "    images_ = torch.cat(images, dim=0)\n",
    "\n",
    "    images_ = images_.to('cpu')\n",
    "\n",
    "    #with autocast(enabled=self.args.fp16_precision):\n",
    "    features = model(images_)  # output shape = (512, 128)\n",
    "    logits, labels = simclr.info_nce_loss(features)\n",
    "    loss = torch.nn.CrossEntropyLoss().to('cpu')(logits, labels)\n",
    "    \n",
    "    break\n",
    "    \n",
    "    #torch.nn.CrossEntropyLoss()(logits[0, :].view(1, -1), labels[0].view(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = (1, 5)\n",
    "maxk = max(topk)\n",
    "\n",
    "batch_size = labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred = logits.topk(5, 1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ = pred.t()\n",
    "correct = pred_.eq(labels.view(1, -1).expand_as(pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_k = correct[:1].reshape(-1).float().sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9766])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_k.mul_(100 / 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxk = max(topk)\n",
    "batch_size = target.size(0)\n",
    "\n",
    "_, pred = output.topk(maxk, 1, True, True)\n",
    "pred = pred.t()\n",
    "correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "res = []\n",
    "for k in topk:\n",
    "    correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "    res.append(correct_k.mul_(100.0 / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.cat([torch.arange(256) for i in range(2)], dim=0)\n",
    "labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "labels = labels.to('cpu')  # output shape = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ = F.normalize(features, dim=1)   # 128 dimensions 에 대해 각 차원별 L2 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = torch.matmul(features_, features_.T)  # in paper : dot product between l2 normalized u and v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.eye(labels.shape[0], dtype=torch.bool).to('cpu')\n",
    "labels_ = labels[~mask].view(labels.shape[0], -1)\n",
    "similarity_matrix_ = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)  # output shape = (512, 511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = similarity_matrix_[labels_.bool()].view(labels.shape[0], -1)\n",
    "negatives = similarity_matrix_[~labels_.bool()].view(similarity_matrix.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.cat([positives, negatives], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.zeros(logits.shape[0], dtype=torch.long).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = logits / 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3266, -2.5380, -0.0374,  1.4999,  1.3031])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.randn(5)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.exp(temp) / torch.exp(temp).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.8828, 0.8326,  ..., 0.8992, 0.9017, 0.7120],\n",
       "        [0.8828, 1.0000, 0.8830,  ..., 0.8647, 0.8769, 0.8240],\n",
       "        [0.8326, 0.8830, 1.0000,  ..., 0.7996, 0.7972, 0.9001],\n",
       "        ...,\n",
       "        [0.8992, 0.8647, 0.7996,  ..., 1.0000, 0.9371, 0.7100],\n",
       "        [0.9017, 0.8769, 0.7972,  ..., 0.9371, 1.0000, 0.7037],\n",
       "        [0.7120, 0.8240, 0.9001,  ..., 0.7100, 0.7037, 1.0000]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_maxtrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_loss(self, features):\n",
    "\n",
    "    labels = torch.cat([torch.arange(256) for i in range(2)], dim=0)\n",
    "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "    labels = labels.to(self.device)\n",
    "\n",
    "    features = F.normalize(features, dim=1)\n",
    "\n",
    "    similarity_matrix = torch.matmul(features, features.T)  # (512, 512)\n",
    "    # assert similarity_matrix.shape == (\n",
    "    #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "    # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "    # discard the main diagonal from both: labels and similarities matrix\n",
    "    mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.device)\n",
    "    labels = labels[~mask].view(labels.shape[0], -1)\n",
    "    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "    # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "    # select and combine multiple positives\n",
    "    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "    # select only the negatives the negatives\n",
    "    negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "    logits = torch.cat([positives, negatives], dim=1)\n",
    "    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.device)\n",
    "\n",
    "    logits = logits / 0.07\n",
    "    return logits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
